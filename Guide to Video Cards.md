Things in IT are measured in FLOPS, not video games framerates. This guide aims to show you what any card is capable of, 
regardless of make, brand or model, which should help with older cards and newer titles calc, which probably nobody is doing.
Figures are approximate, and should be roughly the same as any online game testing site.

Now, you gpu uses pixels per second to show image on resolution. If gp/s is lower than needed, perf will drop. 
It takes 10 GP/s per 1k. Usually Windows come with mirror enabled, so it's double.

1) GP/s for single screen (with mirror enabled):

3840 x 2160 = 6K = 120 GP/s

3200 x 1800 = 5K = 100 GP/s

2560 x 1440 = 4K = 80 GP/s

1920 x 1080 = 3K = 60 GP/s

1280 x 720 = 2K = 40 GP/s

2) TFLOPS

Directx 9 = 1 TFLOPS = 120 fps

Directx 10 = 1 TFLOPS = 60 fps

Directx 11 = 1 TFLOPS = 30 fps

Directx 12 = 1 TFLOPS = 15 fps

3) Precision

16 bit titles = half precision

32 bit titles = single precision

64 bit titles = double precision

4) GT/s Texels per second

10 GT/s = 1 GB VRAM

5)

How to do Math:

GTX 1060 has 8 GB VRAM, 80 GT/s, 80 GP/s and 4 TFLOPS

RX 570 has 8 GB VRAM, 120 GT/s, 40 GP/s and 5 TFLOPS

This basically means GTX 1060 will perform better at higher res or multiple screens, but for mining only, or lower res, RX 570 is a better card.


6)

Where to lookup numbers:

https://en.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units

https://en.wikipedia.org/wiki/List_of_AMD_graphics_processing_units

https://en.wikipedia.org/wiki/List_of_Intel_graphics_processing_units
